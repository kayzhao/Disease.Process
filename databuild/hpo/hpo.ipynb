{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import chain\n",
    "import networkx\n",
    "import requests\n",
    "from mydisease.utils import read_obo\n",
    "from mydisease.utils.common import list2dict\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.mydisease.HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This is copied from do.ipynb with modified parse_xrefs. TODO: make generic and import it\n",
    "def graph_to_d(graph):\n",
    "    \"\"\"\n",
    "    :param graph: A networkx graph made from reading ontology\n",
        "    :type graph: networkx.classes.multidigraph.MultiDiGraph\n",
        "    :return:\n",
    "    \"\"\"\n",
    "    node_link_data = json_graph.node_link_data(graph)\n",
    "    nodes = node_link_data['nodes']\n",
    "\n",
    "    idx_id = {idx: node['id'] for idx,node in enumerate(nodes)}\n",
    "    for link in node_link_data['links']:\n",
    "        # store the edges (links) within the graph\n",
    "        key = link['key']\n",
    "        source = link['source']\n",
    "        target = link['target']\n",
    "\n",
    "        if key not in nodes[source]:\n",
    "            nodes[source][key] = set()\n",
    "        nodes[source][key].add(idx_id[target])\n",
    "\n",
    "    # for mongo insertion\n",
    "    for node in nodes:\n",
    "        node['_id'] = node['id'].lower()\n",
    "        if \"alt_id\" in node:\n",
    "            node['alt_id'] = [x.lower() for x in node['alt_id']]\n",
    "        if \"is_a\" in node:\n",
    "            node['is_a'] = [x.lower() for x in node['is_a']]\n",
    "        if \"property_value\" in node:\n",
    "            del node['property_value']\n",
    "        del node['id']\n",
    "        for k,v in node.items():\n",
    "            if isinstance(v, set):\n",
    "                node[k] = list(v)\n",
    "    d = {node['_id']: node for node in nodes}\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def parse_synonym(line: str):\n",
    "    # line = \"synonym: \\\"The other white meat\\\" EXACT MARKETING_SLOGAN [MEAT:00324, BACONBASE:03021]\"\n",
    "    return line[line.index(\"\\\"\")+1:line.rindex(\"\\\"\")] if line.count(\"\\\"\") == 2 else line\n",
    "\n",
    "\n",
    "def parse_def(line: str):\n",
    "    \"\"\"\n",
    "    Parse definition field.\n",
    "    Returns a tuple(definition, list of crosslink urls)\n",
    "    \n",
    "    >>> parse_def(\"\\\"A description.\\\" [url:http://www.ncbi.goc/123, url:http://www.ncbi.nlm.nih.gov/pubmed/15318016]\")\n",
    "    ('A description.', ['url:http\\\\://www.ncbi.goc/123', 'url:http\\\\://www.ncbi.nlm.nih.gov/pubmed/1531801'])\n",
    "    \n",
    "    \"\"\"\n",
    "    definition = line[line.index(\"\\\"\")+1:line.rindex(\"\\\"\")] if line.count(\"\\\"\") == 2 else line\n",
    "    if line.endswith(\"]\") and line.count(\"[\"):\n",
    "        left_bracket = [m.start() for m in re.finditer('\\[', line)]\n",
    "        right_bracket = [m.start() for m in re.finditer('\\]', line)]\n",
    "        endliststr = line[left_bracket[-1]+1:right_bracket[-1]]\n",
    "        endlist = [x.strip().replace(\"\\\\\\\\\",\"\").replace(\"\\\\\",\"\") for x in endliststr.split(\", \")]\n",
    "        return definition, endlist\n",
    "    else:\n",
    "        return definition, None\n",
    "\n",
    "\n",
    "def parse_xref(xrefs: List[str]):\n",
    "    \"\"\"\n",
    "    Parse xref field. Input is list of strings (xref IDs)\n",
    "    Normalizes prefix strings (MSH -> MESH, ORDO -> Orphanet) and converts prefix to lowercase\n",
    "    Returns dict[ID prefix: list of IDs without prefix]\n",
    "    \n",
    "    >>> parse_xref(['MSH:D006954',  'SNOMEDCT_US_2016_03_01:190781009',  'SNOMEDCT_US_2016_03_01:34349009',  'UMLS_CUI:C0020481'])\n",
    "    {'MESH': ['D006954'],\n",
    "     'SNOMEDCT_US_2016_03_01': ['190781009', '34349009'],\n",
    "     'UMLS_CUI': ['C0020481']}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    xrefs = [x for x in xrefs if \":\" in x]\n",
    "    xrefs = [x.split(\":\",1)[0].lower() + \":\" + x.split(\":\",1)[1] for x in xrefs]\n",
    "    xrefs = [x.split(\" \",1)[0] for x in xrefs] ## <--- this is different between HPO and DO\n",
    "    for n,xref in enumerate(xrefs):\n",
    "        if xref.startswith(\"msh:\"):\n",
    "            xrefs[n] = \"mesh:\" + xref.split(\":\",1)[1]\n",
    "        if xref.startswith(\"ordo:\"):\n",
    "            xrefs[n] = \"orphanet:\" + xref.split(\":\",1)[1]\n",
    "        if xref.startswith(\"umls:\"):\n",
    "            xrefs[n] = \"umls_cui:\" + xref.split(\":\",1)[1]\n",
    "        if xref.startswith(\"icd-10:\"):\n",
    "            xrefs[n] = \"icd10cm:\" + xref.split(\":\",1)[1]\n",
    "    return list2dict(xrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = read_obo(open(\"/home/gstupp/projects/biothings/mydisease/mydisease/data/hp.obo\").readlines())\n",
    "d = graph_to_d(graph)\n",
    "\n",
    "for value in d.values():\n",
    "    if 'xref' in value:\n",
    "        value['xref'] = parse_xref(value['xref'])\n",
    "    if 'synonym' in value:\n",
    "        value['synonym'] = list(map(parse_synonym, value['synonym']))\n",
    "    if 'def' in value:\n",
    "        value['def'],ref = parse_def(value['def'])\n",
    "        if ref:\n",
    "            if 'xref' in value:\n",
    "                value['xref'].update(parse_xref(ref))\n",
    "            else:\n",
    "                value['xref'] = parse_xref(ref)\n",
    "            value['xref'] = {k:v for k,v in value['xref'].items() if k not in {\"hpo\",\"ddd\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mesh': ['D008831'],\n",
       " 'pmid': ['19125436', '9683597'],\n",
       " 'umls_cui': ['C0025958']}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['hp:0000252']['xref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('umls_cui', 3706),\n",
       " ('pmid', 1093),\n",
       " ('mesh', 1066),\n",
       " ('snomedct', 266),\n",
       " ('utoronto', 121),\n",
       " ('meddra', 93),\n",
       " ('goc', 88),\n",
       " ('eurenomics', 64),\n",
       " ('orcid', 40),\n",
       " ('icd10cm', 36),\n",
       " ('mp', 30),\n",
       " ('eom', 19),\n",
       " ('neuromics', 16),\n",
       " ('emedicine', 13),\n",
       " ('epcc', 13),\n",
       " ('ki', 12),\n",
       " ('icm', 10),\n",
       " ('uk', 10),\n",
       " ('nihr', 7),\n",
       " ('uncl', 7),\n",
       " ('monarch', 6),\n",
       " ('ncit', 5),\n",
       " ('http', 5),\n",
       " ('hp', 5),\n",
       " ('mpath', 5),\n",
       " ('isbn', 5),\n",
       " ('https', 4),\n",
       " ('ukt', 4),\n",
       " ('gc', 3),\n",
       " ('icd-o', 3),\n",
       " ('cineas', 3),\n",
       " ('icd-9', 3),\n",
       " ('ukb', 3),\n",
       " ('phenotips', 3),\n",
       " ('icd10', 2),\n",
       " ('doi', 2),\n",
       " ('cochrane', 1),\n",
       " ('nci', 1),\n",
       " ('dsm-iv', 1),\n",
       " ('omim', 1),\n",
       " ('imm', 1),\n",
       " ('www', 1),\n",
       " ('v', 1),\n",
       " ('ordcid', 1),\n",
       " ('orcird', 1),\n",
       " ('isca', 1),\n",
       " ('doid', 1),\n",
       " ('hppo', 1),\n",
       " ('uhpo', 1),\n",
       " ('dd', 1),\n",
       " ('dsm', 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([x.split(\":\")[0] for x in chain(*[x.get('xref',[]) for x in d.values()])]).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fa57855b480>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop()\n",
    "db.insert_many(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'hp:0000252',\n",
       " 'alt_id': ['hp:0001366', 'hp:0005485', 'hp:0005489', 'hp:0005497'],\n",
       " 'comment': 'Head circumference is measured from just above the glabella (the most prominent point on the frontal bone above the root of the nose) to the most posterior prominent point of the occipital bone using a tape measure. Some standard charts are organized by centiles [Hall et al. [2007]], others by standard deviations [Farkas, [1981]]. It is important to add an indication of how far below the normal standard the head circumference is if an accurate assessment of this can be made. Microcephaly is an absolute term. The term relative microcephaly can be used when the head size centile is less than the centile for height, for example, head size at the 3rd centile with height at the 75% for age and sex. On prenatal ultrasound, microcephaly is diagnosed if the head circumference or the biparietal diameter is more than three standard deviations below the mean.',\n",
       " 'def': 'Occipito-frontal (head) circumference (OFC) less than -3 standard deviations compared to appropriate, age matched, normal standards (Ross JJ, Frias JL 1977, PMID:9683597). Alternatively, decreased size of the cranium.',\n",
       " 'is_a': ['hp:0040195', 'hp:0007364'],\n",
       " 'name': 'Microcephaly',\n",
       " 'subset': ['hposlim_core'],\n",
       " 'synonym': ['Abnormally small cranium',\n",
       "  'Abnormally small head',\n",
       "  'Abnormally small skull',\n",
       "  'Decreased circumference of cranium',\n",
       "  'Decreased size of cranium',\n",
       "  'Decreased size of head',\n",
       "  'Decreased size of skull',\n",
       "  'Reduced head circumference',\n",
       "  'small calvarium',\n",
       "  'small cranium',\n",
       "  'Small head',\n",
       "  'Small head circumference',\n",
       "  'Small skull'],\n",
       " 'xref': {'mesh': ['D008831'],\n",
       "  'pmid': ['19125436', '9683597'],\n",
       "  'umls_cui': ['C0025958']}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.find_one('hp:0000252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}